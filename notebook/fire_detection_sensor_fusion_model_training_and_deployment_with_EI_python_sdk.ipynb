{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwKGWt1Wv62Ze1wznnMU8o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SolomonGithu/Arduino-Nano-33-BLE-Sense_responding_to_voice/blob/main/notebook/fire_detection_sensor_fusion_model_training_and_deployment_with_EI_python_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demonstration of sensor fusion by training a model to detect fires using image and temperature data"
      ],
      "metadata": {
        "id": "WGYVH3hcz6BK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please have a look at the [project's documentation](https://docs.edgeimpulse.com/experts/air-quality-and-environmental-projects/fire-detection-sensor-fusion-arduino-nano) for a more detailed overview."
      ],
      "metadata": {
        "id": "72qBCwSzAABS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# You can upload the dataset folder to a Google Drive directory and use it in the notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/Projects/Datasets/fire_detection_sensor_fusion_dataset\"\n",
        "# We can upload the dataset folder to a Google Drive directory\n",
        "base_directory = '/content/gdrive/My Drive/Projects/Datasets/fire_detection_sensor_fusion_dataset'\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "x0iBbHFQMrUR",
        "outputId": "534e8686-2d90-4968-f7b2-81d97c2bf4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# You can upload the dataset folder to a Google Drive directory and use it in the notebook\\nfrom google.colab import drive\\ndrive.mount(\\'/content/gdrive\\')\\n!ls \"/content/gdrive/My Drive/Projects/Datasets/fire_detection_sensor_fusion_dataset\"\\n# We can upload the dataset folder to a Google Drive directory\\nbase_directory = \\'/content/gdrive/My Drive/Projects/Datasets/fire_detection_sensor_fusion_dataset\\'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forcefully delete a folder\n",
        "#!rm -rf '/content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion'"
      ],
      "metadata": {
        "id": "EUN9PXDC-NgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository with the dataset\n",
        "! git clone https://github.com/SolomonGithu/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Req0bY-Ex_N-",
        "outputId": "1a248269-1dfb-483b-d2a9-9a71bc06f679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion'...\n",
            "remote: Enumerating objects: 200, done.\u001b[K\n",
            "remote: Counting objects: 100% (200/200), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 200 (delta 15), reused 188 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (200/200), 21.70 MiB | 35.60 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List directories\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nazFHA4SzKnK",
        "outputId": "d2aa3bae-291a-4324-bb93-4c02abab4765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwSrAZh_L3a-"
      },
      "outputs": [],
      "source": [
        "# set the directory with the dataset\n",
        "#base_directory = '/content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset'\n",
        "base_directory = '/content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install edgeimpulse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HaldGuqeh62",
        "outputId": "c4834777-06b8-4a60-e759-38e77cfeb096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edgeimpulse\n",
            "  Downloading edgeimpulse-1.0.13-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting edgeimpulse-api==1.53.13 (from edgeimpulse)\n",
            "  Downloading edgeimpulse_api-1.53.13-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-socketio[client]<6.0.0,>=5.8.0 (from edgeimpulse)\n",
            "  Downloading python_socketio-5.11.3-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from edgeimpulse) (2.31.0)\n",
            "Collecting aenum<4.0.0,>=3.1.11 (from edgeimpulse-api==1.53.13->edgeimpulse)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.10.2 (from edgeimpulse-api==1.53.13->edgeimpulse)\n",
            "  Downloading pydantic-1.10.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python_dateutil<3.0.0,>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from edgeimpulse-api==1.53.13->edgeimpulse) (2.8.2)\n",
            "Collecting urllib3<2.0.0,>=1.25.3 (from edgeimpulse-api==1.53.13->edgeimpulse)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading python_engineio-4.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->edgeimpulse) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.2->edgeimpulse-api==1.53.13->edgeimpulse) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python_dateutil<3.0.0,>=2.5.3->edgeimpulse-api==1.53.13->edgeimpulse) (1.16.0)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio[client]<6.0.0,>=5.8.0->edgeimpulse)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum, urllib3, pydantic, h11, wsproto, edgeimpulse-api, simple-websocket, python-engineio, python-socketio, edgeimpulse\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.8.2\n",
            "    Uninstalling pydantic-2.8.2:\n",
            "      Successfully uninstalled pydantic-2.8.2\n",
            "Successfully installed aenum-3.1.15 edgeimpulse-1.0.13 edgeimpulse-api-1.53.13 h11-0.14.0 pydantic-1.10.17 python-engineio-4.9.1 python-socketio-5.11.3 simple-websocket-1.0.0 urllib3-1.26.19 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Conv2D, MaxPooling2D, Dropout, Lambda\n",
        "import tensorflow as tf\n",
        "import edgeimpulse as ei"
      ],
      "metadata": {
        "id": "qLmYvK94N4ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ei.API_KEY = \"ei_..\" # Put your Edge Impulse project API key. You can obtain it from the Dashboard page in the Keys section"
      ],
      "metadata": {
        "id": "wNjzoxxReFOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV files with the temperature values\n",
        "fire_temperature_data = pd.read_csv(base_directory + '/fire/fire.csv')\n",
        "safe_environment_temperature_data = pd.read_csv(base_directory + '/safe_environment/safe_environment.csv')"
      ],
      "metadata": {
        "id": "lzUgFbayNvsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a label column to each dataframe\n",
        "fire_temperature_data['label'] = 'fire'\n",
        "safe_environment_temperature_data['label'] = 'safe_environment'"
      ],
      "metadata": {
        "id": "MABxTxEHSRwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image width, height and channels\n",
        "image_width = 32\n",
        "image_height = 32\n",
        "image_channels = 1 # 1 for grayscale, 3 for RGB"
      ],
      "metadata": {
        "id": "lUkBBiu7QbH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the dataframes with fire, \"normal\" temperatures and the their class labels\n",
        "data = pd.concat([fire_temperature_data, safe_environment_temperature_data], ignore_index=True)\n",
        "classes = [\"fire\", \"safe_environment\"]"
      ],
      "metadata": {
        "id": "lIYMRRI6U4Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode string labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data['label'])\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(\"Number of classes = \", num_classes)"
      ],
      "metadata": {
        "id": "G0NVldJ0VAwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e67e9d-59d6-4d23-eb6e-32c5683b83d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes =  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(filepath):\n",
        "    print(\"file loaded : \", filepath)\n",
        "    if image_channels == 1:\n",
        "      image = load_img(filepath, color_mode='grayscale', target_size=(image_width, image_height))  # Ensure grayscale\n",
        "    else:\n",
        "      image = load_img(filepath, target_size=(image_width, image_height))  # Resize the image\n",
        "    image = img_to_array(image)\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image"
      ],
      "metadata": {
        "id": "hOh-wQwiOMC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load images of different classes and from multiple directories\n",
        "def load_images_from_directories(base_directory, directories, filenames):\n",
        "    images = []\n",
        "    for directory in directories:\n",
        "        dir_path = os.path.join(base_directory, directory)\n",
        "        for fname in filenames:\n",
        "            filepath = os.path.join(dir_path, str(fname) + '.jpg')\n",
        "            if os.path.exists(filepath):  # Check if the file exists\n",
        "                image = load_and_preprocess_image(filepath)\n",
        "                images.append(image)\n",
        "            else:\n",
        "                print(f\"File {filepath} does not exist. Skipping.\")\n",
        "    return np.array(images)\n",
        "\n",
        "# List of directories to load images from\n",
        "directories = ['fire', 'safe_environment']\n",
        "\n",
        "# Ensure filenames are unique and correspond to the right number of samples\n",
        "filenames = data['filename'].unique()\n",
        "images = load_images_from_directories(base_directory, directories, filenames)\n",
        "\n",
        "# Check if the number of images matches the number of rows in the data\n",
        "if len(images) != len(data):\n",
        "    raise ValueError(f\"Number of images ({len(images)}) does not match the number of rows in the data ({len(data)})\")\n",
        "\n",
        "temperatures = data['temperature'].values.reshape(-1, 1)\n",
        "labels = to_categorical(data['label'].values, num_classes=num_classes)  # One-hot encode the labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asK89sk470WZ",
        "outputId": "f7c5fdb3-7a35-478d-b219-964ff5c4d265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/1.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/2.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/3.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/4.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/5.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/6.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/7.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/8.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/9.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/10.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/11.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/12.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/13.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/14.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/15.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/16.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/17.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/18.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/19.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/20.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/21.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/22.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/23.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/24.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/25.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/26.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/27.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/28.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/29.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/30.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/31.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/32.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/33.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/34.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/35.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/36.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/37.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/38.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/39.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/40.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/41.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/42.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/43.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/44.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/45.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/46.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/47.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/48.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/49.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/50.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/51.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/52.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/53.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/54.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/55.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/56.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/57.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/58.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/59.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/fire/60.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/1.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/2.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/3.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/4.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/5.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/6.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/7.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/8.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/9.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/10.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/11.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/12.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/13.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/14.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/15.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/16.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/17.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/18.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/19.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/20.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/21.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/22.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/23.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/24.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/25.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/26.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/27.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/28.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/29.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/30.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/31.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/32.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/33.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/34.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/35.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/36.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/37.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/38.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/39.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/40.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/41.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/42.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/43.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/44.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/45.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/46.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/47.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/48.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/49.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/50.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/51.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/52.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/53.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/54.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/55.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/56.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/57.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/58.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/59.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment/60.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Flatten the images and concatenate with temperatures\n",
        "  flattened_images = images.reshape(images.shape[0], -1)\n",
        "  print(f\"Flattened images shape: {flattened_images.shape}\")\n",
        "  combined_inputs = np.concatenate([flattened_images, temperatures], axis=1)\n",
        "  print(f\"Combined inputs shape: {combined_inputs.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSWzwleXJaiz",
        "outputId": "869f7064-8eda-47e6-b494-b258dab4845c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened images shape: (120, 1024)\n",
            "Combined inputs shape: (120, 1025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads a simple model, has 100% training and testing accuracy.\n",
        "# Though during inference the model classifies all image data it was not trained with as fire (biased on fire) :(\n",
        "def load_custom_multi_input_CNN_model():\n",
        "  # Define the combined input layer\n",
        "  input_layer = Input(shape=(image_width * image_height * image_channels + 1,))\n",
        "\n",
        "  # Slice the combined input into image and temperature tensors\n",
        "  image_tensor = Lambda(lambda x: x[:, :-1])(input_layer)\n",
        "  temp_tensor = Lambda(lambda x: x[:, -1:])(input_layer)\n",
        "\n",
        "  # Reshape the image tensor to the original image shape\n",
        "  image_tensor = Lambda(lambda x: tf.reshape(x, [-1, image_width, image_height, image_channels]))(image_tensor)\n",
        "\n",
        "  # Image input branch\n",
        "  x = Conv2D(32, (3, 3), activation='relu')(image_tensor)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  # Temperature input branch\n",
        "  y = Dense(32, activation='relu')(temp_tensor)\n",
        "\n",
        "  # Combine branches\n",
        "  combined = Concatenate()([x, y])\n",
        "  z = Dense(128, activation='relu')(combined)\n",
        "  z = Dropout(0.5)(z)\n",
        "  z = Dense(num_classes, activation='softmax')(z)\n",
        "\n",
        "  # Define the model\n",
        "  model = Model(inputs=input_layer, outputs=z)\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\"\"\"\"\n",
        "# Load a MobileNet model and apply tensor slicing\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "def load_MobileNet_model():\n",
        "    # Define the combined input layer\n",
        "    input_layer = Input(shape=(image_width * image_height * image_channels + 1,))\n",
        "\n",
        "    # Slice the combined input into image and temperature tensors\n",
        "    image_tensor = Lambda(lambda x: x[:, :-1])(input_layer)\n",
        "    temp_tensor = Lambda(lambda x: x[:, -1:])(input_layer)\n",
        "\n",
        "    # Reshape the image tensor to the original image shape\n",
        "    image_tensor = Lambda(lambda x: tf.reshape(x, [-1, image_width, image_height, image_channels]))(image_tensor)\n",
        "\n",
        "    if image_channels == 1:\n",
        "      # Repeat the grayscale channel three times\n",
        "      image_tensor = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(image_tensor)\n",
        "\n",
        "    # Load the MobileNetV1 model\n",
        "    mobilenet = MobileNet(input_shape=(image_width, image_height, 3), alpha=0.25, include_top=False, pooling='avg')(image_tensor)\n",
        "\n",
        "    # Temperature input branch\n",
        "    temp_dense = Dense(32, activation='relu')(temp_tensor)\n",
        "\n",
        "    # Combine branches\n",
        "    combined = Concatenate()([mobilenet, temp_dense])\n",
        "    z = Dense(128, activation='relu')(combined)\n",
        "    z = Dropout(0.5)(z)\n",
        "    z = Dense(num_classes, activation='softmax')(z)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=input_layer, outputs=z)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Load a MobileNet model and apply tensor slicing\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "def load_MobileNetV2_model():\n",
        "    # Define the combined input layer\n",
        "    input_layer = Input(shape=(image_width * image_height * image_channels + 1,))\n",
        "\n",
        "    # Slice the combined input into image and temperature tensors\n",
        "    image_tensor = Lambda(lambda x: x[:, :-1])(input_layer)\n",
        "    temp_tensor = Lambda(lambda x: x[:, -1:])(input_layer)\n",
        "\n",
        "    # Reshape the image tensor to the original image shape\n",
        "    image_tensor = Lambda(lambda x: tf.reshape(x, [-1, image_width, image_height, image_channels]))(image_tensor)\n",
        "\n",
        "    if image_channels == 1:\n",
        "      # Repeat the grayscale channel three times\n",
        "      image_tensor = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(image_tensor)\n",
        "\n",
        "    # Load the MobileNetV2 model\n",
        "    mobilenet = MobileNetV2(input_shape=(image_width, image_height, 3), alpha=0.35, include_top=False, pooling='avg')(image_tensor)\n",
        "\n",
        "    # Temperature input branch\n",
        "    temp_dense = Dense(32, activation='relu')(temp_tensor)\n",
        "\n",
        "    # Combine branches\n",
        "    combined = Concatenate()([mobilenet, temp_dense])\n",
        "    z = Dense(128, activation='relu')(combined)\n",
        "    z = Dropout(0.5)(z)\n",
        "    z = Dense(num_classes, activation='softmax')(z)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=input_layer, outputs=z)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "lZy3zaLpoWDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "184fb00b-2f15-4722-97ea-708bcf0efdea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\n# Load a MobileNet model and apply tensor slicing\\nfrom tensorflow.keras.applications import MobileNet\\ndef load_MobileNet_model():\\n    # Define the combined input layer\\n    input_layer = Input(shape=(image_width * image_height * image_channels + 1,))\\n\\n    # Slice the combined input into image and temperature tensors\\n    image_tensor = Lambda(lambda x: x[:, :-1])(input_layer)\\n    temp_tensor = Lambda(lambda x: x[:, -1:])(input_layer)\\n\\n    # Reshape the image tensor to the original image shape\\n    image_tensor = Lambda(lambda x: tf.reshape(x, [-1, image_width, image_height, image_channels]))(image_tensor)\\n\\n    if image_channels == 1:\\n      # Repeat the grayscale channel three times\\n      image_tensor = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(image_tensor)\\n\\n    # Load the MobileNetV1 model\\n    mobilenet = MobileNet(input_shape=(image_width, image_height, 3), alpha=0.25, include_top=False, pooling=\\'avg\\')(image_tensor)\\n\\n    # Temperature input branch\\n    temp_dense = Dense(32, activation=\\'relu\\')(temp_tensor)\\n\\n    # Combine branches\\n    combined = Concatenate()([mobilenet, temp_dense])\\n    z = Dense(128, activation=\\'relu\\')(combined)\\n    z = Dropout(0.5)(z)\\n    z = Dense(num_classes, activation=\\'softmax\\')(z)\\n\\n    # Define the model\\n    model = Model(inputs=input_layer, outputs=z)\\n\\n    # Compile the model\\n    model.compile(optimizer=\\'adam\\', loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n    return model\\n\\n\\n# Load a MobileNet model and apply tensor slicing\\nfrom tensorflow.keras.applications import MobileNetV2\\ndef load_MobileNetV2_model():\\n    # Define the combined input layer\\n    input_layer = Input(shape=(image_width * image_height * image_channels + 1,))\\n\\n    # Slice the combined input into image and temperature tensors\\n    image_tensor = Lambda(lambda x: x[:, :-1])(input_layer)\\n    temp_tensor = Lambda(lambda x: x[:, -1:])(input_layer)\\n\\n    # Reshape the image tensor to the original image shape\\n    image_tensor = Lambda(lambda x: tf.reshape(x, [-1, image_width, image_height, image_channels]))(image_tensor)\\n\\n    if image_channels == 1:\\n      # Repeat the grayscale channel three times\\n      image_tensor = Lambda(lambda x: tf.image.grayscale_to_rgb(x))(image_tensor)\\n\\n    # Load the MobileNetV2 model\\n    mobilenet = MobileNetV2(input_shape=(image_width, image_height, 3), alpha=0.35, include_top=False, pooling=\\'avg\\')(image_tensor)\\n\\n    # Temperature input branch\\n    temp_dense = Dense(32, activation=\\'relu\\')(temp_tensor)\\n\\n    # Combine branches\\n    combined = Concatenate()([mobilenet, temp_dense])\\n    z = Dense(128, activation=\\'relu\\')(combined)\\n    z = Dropout(0.5)(z)\\n    z = Dense(num_classes, activation=\\'softmax\\')(z)\\n\\n    # Define the model\\n    model = Model(inputs=input_layer, outputs=z)\\n\\n    # Compile the model\\n    model.compile(optimizer=\\'adam\\', loss=\\'categorical_crossentropy\\', metrics=[\\'accuracy\\'])\\n\\n    return model\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_custom_multi_input_CNN_model()\n",
        "#model = load_MobileNet_model()\n",
        "#model = load_MobileNetV2_model()\n",
        "#model.get_weights() # print the model weights\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8ZntjsFo341",
        "outputId": "5c1bda82-a65e-4c7f-a0dc-f7e92769ebbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1025)]               0         []                            \n",
            "                                                                                                  \n",
            " lambda (Lambda)             (None, 1024)                 0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_2 (Lambda)           (None, 32, 32, 1)            0         ['lambda[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 30, 30, 32)           320       ['lambda_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)           0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)           18496     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)             0         ['conv2d_1[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)            73856     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)            0         ['conv2d_2[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 1)                    0         ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 512)                  0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 32)                   64        ['lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 544)                  0         ['flatten[0][0]',             \n",
            "                                                                     'dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  69760     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 128)                  0         ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2)                    258       ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 162754 (635.76 KB)\n",
            "Trainable params: 162754 (635.76 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_inputs, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "6_Jwv3jtSn5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "training_epochs = 50\n",
        "batch_size = 32\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=training_epochs, batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuAAlMI6S2w4",
        "outputId": "ae2423dc-04c7-442c-f25b-11781cc71b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 3s 218ms/step - loss: 1.5627 - accuracy: 0.5000 - val_loss: 0.7013 - val_accuracy: 0.5417\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 1.2898 - accuracy: 0.5208 - val_loss: 0.5544 - val_accuracy: 0.5417\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.8589 - accuracy: 0.6458 - val_loss: 0.2931 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.6081 - accuracy: 0.7188 - val_loss: 0.2028 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 110ms/step - loss: 0.5681 - accuracy: 0.7708 - val_loss: 0.1558 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.2924 - accuracy: 0.8854 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.2947 - accuracy: 0.9271 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.1185 - accuracy: 0.9688 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0766 - accuracy: 0.9896 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 0.0973 - accuracy: 0.9792 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 0.0729 - accuracy: 0.9896 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 133ms/step - loss: 0.0811 - accuracy: 0.9896 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 0.0615 - accuracy: 0.9896 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 0.0610 - accuracy: 0.9896 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 118ms/step - loss: 0.0525 - accuracy: 0.9896 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 124ms/step - loss: 0.0528 - accuracy: 0.9896 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 0.0690 - accuracy: 0.9896 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 152ms/step - loss: 0.0623 - accuracy: 0.9896 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 116ms/step - loss: 0.0663 - accuracy: 0.9896 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 159ms/step - loss: 0.0547 - accuracy: 0.9896 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 122ms/step - loss: 0.0703 - accuracy: 0.9896 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 0.0500 - accuracy: 0.9896 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 0.0523 - accuracy: 0.9896 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 106ms/step - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 145ms/step - loss: 0.0511 - accuracy: 0.9896 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.0690 - accuracy: 0.9896 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 157ms/step - loss: 0.0691 - accuracy: 0.9896 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 111ms/step - loss: 0.0596 - accuracy: 0.9896 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.0645 - accuracy: 0.9896 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 132ms/step - loss: 0.0618 - accuracy: 0.9896 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 175ms/step - loss: 0.0605 - accuracy: 0.9896 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 204ms/step - loss: 0.0586 - accuracy: 0.9896 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 181ms/step - loss: 0.0594 - accuracy: 0.9896 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 181ms/step - loss: 0.0580 - accuracy: 0.9896 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 1s 208ms/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 147ms/step - loss: 0.0504 - accuracy: 0.9896 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 215ms/step - loss: 0.0667 - accuracy: 0.9896 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 0.0516 - accuracy: 0.9896 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 277ms/step - loss: 0.0424 - accuracy: 0.9896 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 149ms/step - loss: 0.0710 - accuracy: 0.9896 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 182ms/step - loss: 0.0580 - accuracy: 0.9896 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 214ms/step - loss: 0.0721 - accuracy: 0.9896 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 0.0750 - accuracy: 0.9896 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 1s 269ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 177ms/step - loss: 0.0798 - accuracy: 0.9896 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 143ms/step - loss: 0.0887 - accuracy: 0.9896 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 113ms/step - loss: 0.0431 - accuracy: 0.9896 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 107ms/step - loss: 0.0571 - accuracy: 0.9896 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 0.0589 - accuracy: 0.9896 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 0.0615 - accuracy: 0.9896 - val_loss: 0.0060 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw95uSOTTYDm",
        "outputId": "ac51c538-def3-4a61-83b4-212bd8c9a119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Test accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_environment(image_path, temperature, output_file='input_features.txt'):\n",
        "    print(\"Testing the model on an image.....\")\n",
        "    print(f'file loaded: {image_path}')\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    new_image = load_and_preprocess_image(image_path).flatten()\n",
        "\n",
        "    # Flatten the temperature array to be a single value array\n",
        "    new_temperature = np.array([temperature])\n",
        "\n",
        "    # Concatenate the image and temperature arrays\n",
        "    combined_input = np.concatenate([new_image, new_temperature], axis=0)\n",
        "\n",
        "    # Print the input features separated by commas, for debugging!\n",
        "    #print(','.join(map(str, combined_input)))\n",
        "\n",
        "    # Save the  input features separated by commas to a .txt file, for debugging!\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(','.join(map(str, combined_input)))\n",
        "\n",
        "    # Reshape combined input to match the expected input shape\n",
        "    combined_input = combined_input.reshape(1, -1)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(combined_input)\n",
        "\n",
        "    # Get confidence scores\n",
        "    confidence_scores = prediction[0]\n",
        "\n",
        "    # Get the predicted class index and label\n",
        "    predicted_class_index = np.argmax(confidence_scores)\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "    return predicted_label, confidence_scores"
      ],
      "metadata": {
        "id": "p3QC8IzQZ5b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage, test fire cases\n",
        "#image_path = base_directory + '/' + 'fire_test' + '/' + '1.jpg' # Test image\n",
        "#temperature = 68.0  # Test temperature value. Obtained the same time as the test image\n",
        "\n",
        "# Example usage, test safe environment cases\n",
        "image_path = base_directory + '/' + 'safe_environment_test' + '/' + '7.jpg' # Test image\n",
        "temperature = 27.0  # Test temperature value. Obtained the same time as the test image\n",
        "\n",
        "prediction, confidence_scores = classify_environment(image_path, temperature, output_file='input_features.txt')\n",
        "print(confidence_scores)\n",
        "print('The model classified the environment as ' + prediction + ' with a confidence of ' + str(confidence_scores[np.argmax(confidence_scores)]))"
      ],
      "metadata": {
        "id": "nUcCSvRUZ8OQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e983a083-bbfe-4bbf-a3f1-76fd7fca4490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model on an image.....\n",
            "file loaded: /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment_test/7.jpg\n",
            "file loaded :  /content/Arduino_Nano_33_BLE_Sense_fire_detection_using_sensor_fusion/fire_detection_sensor_fusion_dataset_modified/safe_environment_test/7.jpg\n",
            "1/1 [==============================] - 0s 324ms/step\n",
            "[0.01151043 0.98848957]\n",
            "The model classified the environment as safe_environment with a confidence of 0.98848957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Edge Impulse Python SDK"
      ],
      "metadata": {
        "id": "BjUIziXMO7gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_profile_devices()"
      ],
      "metadata": {
        "id": "9hNIGsWTe-Yt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ac882c-0fe6-42cc-992d-7153c215bf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alif-he',\n",
              " 'alif-hp',\n",
              " 'arduino-nano-33-ble',\n",
              " 'arduino-nicla-vision',\n",
              " 'arduino-nicla-vision-m4',\n",
              " 'portenta-h7',\n",
              " 'brainchip-akd1000',\n",
              " 'brickml',\n",
              " 'cortex-m4f-80mhz',\n",
              " 'cortex-m7-216mhz',\n",
              " 'espressif-esp32',\n",
              " 'himax-we-i',\n",
              " 'infineon-cy8ckit-062s2',\n",
              " 'infineon-cy8ckit-062-ble',\n",
              " 'mbp-16-2020',\n",
              " 'memryx-mx3',\n",
              " 'microchip-sama7g54',\n",
              " 'nordic-nrf52840-dk',\n",
              " 'nordic-nrf5340-dk',\n",
              " 'nordic-nrf9160-dk',\n",
              " 'jetson-nano',\n",
              " 'jetson-orin-nx',\n",
              " 'jetson-orin-nano',\n",
              " 'openmv-h7p',\n",
              " 'particle-boron',\n",
              " 'particle-p2',\n",
              " 'raspberry-pi-4',\n",
              " 'raspberry-pi-rp2040',\n",
              " 'renesas-ck-ra6m5',\n",
              " 'renesas-ek-ra8d1',\n",
              " 'renesas-rzg2l',\n",
              " 'renesas-rzv2l-cpu',\n",
              " 'renesas-rzv2l',\n",
              " 'st-iot-discovery-kit',\n",
              " 'seeed-sense-cap',\n",
              " 'wio-terminal',\n",
              " 'seeed-vision-ai',\n",
              " 'silabs-xg24',\n",
              " 'silabs-thunderboard-sense-2',\n",
              " 'sony-spresense',\n",
              " 'synaptics-ka10000',\n",
              " 'ti-am62a',\n",
              " 'ti-am68a',\n",
              " 'ti-launchxl',\n",
              " 'ti-tda4vm',\n",
              " 'neox']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the available profile target devices\n",
        "ei.model.list_deployment_targets()"
      ],
      "metadata": {
        "id": "TcOQi3z1fSPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20bc8b7f-6d1d-4cc7-9826-b3bbb2aacf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zip',\n",
              " 'arduino',\n",
              " 'cubemx',\n",
              " 'wasm',\n",
              " 'wasm-browser-simd',\n",
              " 'wasm-node-simd',\n",
              " 'tensorrt',\n",
              " 'ethos-alif-ensemble-e7-hp',\n",
              " 'ethos-alif-ensemble-e7-he',\n",
              " 'ethos-alif-ensemble-e7-he-cmsis-pack',\n",
              " 'ethos-alif-ensemble-e7-hp-cmsis-pack',\n",
              " 'ethos-himax-wiseeye2',\n",
              " 'synaptics-tensaiflow-lib',\n",
              " 'meta-tf',\n",
              " 'memryx-dfp',\n",
              " 'tidl-lib-am62a',\n",
              " 'tidl-lib-am68a',\n",
              " 'slcc',\n",
              " 'think-silicon-neox',\n",
              " 'arduino-nano-33-ble-sense',\n",
              " 'arduino-nicla-vision',\n",
              " 'runner-linux-aarch64-advantech-icam540',\n",
              " 'espressif-esp32',\n",
              " 'raspberry-pi-rp2040',\n",
              " 'silabs-xg24',\n",
              " 'infineon-cy8ckit-062s2',\n",
              " 'infineon-cy8ckit-062-ble',\n",
              " 'nordic-thingy53',\n",
              " 'nordic-thingy53-nrf7002eb',\n",
              " 'sony-spresense-commonsense',\n",
              " 'renesas-ck-ra6m5',\n",
              " 'brickml',\n",
              " 'brickml-module',\n",
              " 'alif-ensemble-e7',\n",
              " 'runner-linux-aarch64',\n",
              " 'runner-linux-armv7',\n",
              " 'runner-linux-x86_64',\n",
              " 'runner-linux-aarch64-akd1000',\n",
              " 'runner-linux-x86_64-akd1000',\n",
              " 'runner-mac-x86_64',\n",
              " 'runner-linux-aarch64-tda4vm',\n",
              " 'runner-linux-aarch64-am62a',\n",
              " 'particle',\n",
              " 'iar',\n",
              " 'runner-linux-aarch64-am68a',\n",
              " 'cmsis-package',\n",
              " 'runner-linux-aarch64-jetson-nano',\n",
              " 'runner-linux-aarch64-rzg2l',\n",
              " 'runner-linux-aarch64-jetson-orin',\n",
              " 'runner-linux-aarch64-jetson-orin-6-0']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate the RAM, ROM, and inference time for our model on the target hardware family\n",
        "try:\n",
        "    profile = ei.model.profile(model=model,\n",
        "                              device='arduino-nano-33-ble')\n",
        "    print(profile.summary())\n",
        "except Exception as e:\n",
        "    print(f\"Could not profile: {e}\")"
      ],
      "metadata": {
        "id": "bmnYVhCwefEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d46ee6-a782-4208-9f4d-db377536006f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target results for float32:\n",
            "===========================\n",
            "{\n",
            "    \"device\": \"arduino-nano-33-ble\",\n",
            "    \"tfliteFileSizeBytes\": 656412,\n",
            "    \"isSupportedOnMcu\": true,\n",
            "    \"memory\": {\n",
            "        \"tflite\": {\n",
            "            \"ram\": 178939,\n",
            "            \"rom\": 711544,\n",
            "            \"arenaSize\": 178547\n",
            "        },\n",
            "        \"eon\": {\n",
            "            \"ram\": 146904,\n",
            "            \"rom\": 682584\n",
            "        }\n",
            "    },\n",
            "    \"timePerInferenceMs\": 6800\n",
            "}\n",
            "\n",
            "\n",
            "Performance on device types:\n",
            "============================\n",
            "{\n",
            "    \"variant\": \"float32\",\n",
            "    \"lowEndMcu\": {\n",
            "        \"description\": \"Estimate for a Cortex-M0+ or similar, running at 40MHz\",\n",
            "        \"timePerInferenceMs\": 17995,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 178747,\n",
            "                \"rom\": 699768\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 146760,\n",
            "                \"rom\": 679320\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"highEndMcu\": {\n",
            "        \"description\": \"Estimate for a Cortex-M7 or other high-end MCU/DSP, running at 240MHz\",\n",
            "        \"timePerInferenceMs\": 246,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 178939,\n",
            "                \"rom\": 711544\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 146904,\n",
            "                \"rom\": 682584\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"highEndMcuPlusAccelerator\": {\n",
            "        \"description\": \"Most accelerators only accelerate quantized models.\",\n",
            "        \"timePerInferenceMs\": 246,\n",
            "        \"memory\": {\n",
            "            \"tflite\": {\n",
            "                \"ram\": 178939,\n",
            "                \"rom\": 711544\n",
            "            },\n",
            "            \"eon\": {\n",
            "                \"ram\": 146904,\n",
            "                \"rom\": 682584\n",
            "            }\n",
            "        },\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"mpu\": {\n",
            "        \"description\": \"Estimate for a Cortex-A72, x86 or other mid-range microprocessor running at 1.5GHz\",\n",
            "        \"timePerInferenceMs\": 5,\n",
            "        \"rom\": 656412.0,\n",
            "        \"supported\": true\n",
            "    },\n",
            "    \"gpuOrMpuAccelerator\": {\n",
            "        \"description\": \"Estimate for a GPU or high-end neural network accelerator\",\n",
            "        \"timePerInferenceMs\": 1,\n",
            "        \"rom\": 656412.0,\n",
            "        \"supported\": true\n",
            "    }\n",
            "}\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Convert the model to a TensorFlow Lite model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "# Estimate the RAM, ROM, and inference time for the TensorFlow Lite model on the target hardware family\n",
        "try:\n",
        "    profile = ei.model.profile(model=tflite_model,\n",
        "                              device='arduino-nano-33-ble')\n",
        "    print(profile.summary())\n",
        "except Exception as e:\n",
        "    print(f\"Could not profile: {e}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "HPfElF_IaxDi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2079c855-3716-48c6-af8c-a572ebb818c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Convert the model to a TensorFlow Lite model\\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\\ntflite_model = converter.convert()\\n\\n# Save the model.\\nwith open(\\'model.tflite\\', \\'wb\\') as f:\\n  f.write(tflite_model)\\n\\n# Estimate the RAM, ROM, and inference time for the TensorFlow Lite model on the target hardware family\\ntry:\\n    profile = ei.model.profile(model=tflite_model,\\n                              device=\\'arduino-nano-33-ble\\')\\n    print(profile.summary())\\nexcept Exception as e:\\n    print(f\"Could not profile: {e}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('saved_model')      # save model in SavedModel format"
      ],
      "metadata": {
        "id": "6YBakT4fj-__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# download the model as zip file\n",
        "from google.colab import files\n",
        "!zip -r /content/saved_model.zip /content/saved_model\n",
        "#files.download('saved_model.zip')\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xR1faRmtkSNp",
        "outputId": "261a67a5-2ed2-4c44-9911-31486ad91423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import files\\n!zip -r /content/saved_model.zip /content/saved_model\\n#files.download('saved_model.zip')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}